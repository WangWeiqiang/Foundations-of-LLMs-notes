# Foundations-of-LLMs-notes
大模型基础（毛玉仁，高云君等著）学习笔记

## 📚 项目简介

本项目以**幻灯片式**的方式解读《大模型基础》这本书中的核心知识点，通过图形化、通俗化的讲解，帮助读者更好地理解大语言模型的原理和实现。

## 🎯 学习目标

- 用**形象化的图表**理解复杂的模型架构
- 用**通俗的语言**解释数学公式背后的含义
- 通过**实例和代码**加深对原理的理解
- 建立**系统化的知识体系**

## 📖 章节导航

### [第一章：大语言模型简介](./slides/ch01-introduction/README.md)
- 什么是大语言模型？
- 发展历程与里程碑
- 核心概念与术语
- 应用场景

### [第二章：Transformer架构详解](./slides/ch02-transformer/README.md)
- 自注意力机制（Self-Attention）
- 多头注意力（Multi-Head Attention）
- 位置编码（Position Encoding）
- 前馈神经网络（Feed-Forward Network）

### [第三章：模型训练基础](./slides/ch03-training/README.md)
- 损失函数与优化目标
- 反向传播算法
- 优化器选择（Adam、AdamW等）
- 学习率调度策略

### [第四章：微调技术](./slides/ch04-finetuning/README.md)
- 迁移学习原理
- 全量微调 vs 参数高效微调
- LoRA、Adapter等技术
- Prompt Engineering

## 🎨 使用说明

每个章节都包含：
- 📊 **概念图解**：用图表展示核心概念
- 🔢 **公式解读**：将数学公式转化为直观理解
- 💡 **实例演示**：通过具体例子说明原理
- 💻 **代码片段**：关键实现的代码示例

## 🤝 贡献指南

欢迎提交 Issue 和 Pull Request 来完善这份学习笔记！

## 📄 许可证

本项目仅供学习交流使用。
